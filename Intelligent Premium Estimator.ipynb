{"cells":[{"cell_type":"markdown","source":["# Preparations"],"metadata":{"id":"kbr2B9teyylT"}},{"cell_type":"markdown","source":["##Install Packages"],"metadata":{"id":"yQvEmM6jgkIJ"}},{"cell_type":"code","source":["# install  necessary packages\n","!pip install ipympl  pandas scikit-learn tensorflow colorama art"],"metadata":{"id":"1aKeQfTNo3O1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Import Packages and Setup Constants"],"metadata":{"id":"uSA7Pxf3uE4y"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.preprocessing import LabelEncoder, PolynomialFeatures\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import StandardScaler\n","import tensorflow as tf\n","from tensorflow.keras import regularizers\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow import keras\n","from art import *\n","import sys\n","import os\n","from colorama import Fore, Style\n","import warnings\n","\n","filepath = \"insurance.csv\"\n","\n","\n","\n","\n","# Text formatting\n","BOLD = Style.BRIGHT\n","END = Style.RESET_ALL\n","\n","# Text colors\n","GREEN = Fore.GREEN\n","RED = Fore.RED\n","PURPLE = Fore.MAGENTA\n","YELLOW = Fore.YELLOW\n","BLUE = Fore.CYAN\n","\n","\n","# Pre-formatted strings\n","str_separator = f\"\\n{PURPLE}================================================{END}\\n\"\n","#str_pressEnter = f\"\\n\\n{BLUE}Press ENTER to continue...{END}\" # uncomment when running outside of the notebook environment\n","#str_choiceSelection = f\"{BLUE}Enter your choice: {END}\"\n","str_pressEnter = f\"\\n\\nPress ENTER to continue...\"\n","str_choiceSelection = f\"Enter your choice: \"\n","\n","\n","# Test dataset, not seen during training\n","test_dataset = [\n","    [25, 'male', 26.22, 0, 'no', 'northeast', 2721.3208],\n","    [64, 'female', 39.33, 0, 'no', 'northeast', 14901.5167],\n","    [30, 'female', 19.95, 3, 'no', 'northwest', 5693.4305],\n","    [57, 'female', 23.98, 1, 'no', 'southeast', 22192.43711],\n","    [31, 'male', 27.645, 2, 'no', 'northeast', 5031.26955],\n","    [22, 'male', 52.58, 1, 'yes', 'southeast', 44501.3982],\n","    [32, 'female', 41.1, 0, 'no', 'southwest', 3989.841],\n","    [33, 'male', 35.75, 1, 'yes', 'southeast', 38282.7495],\n","    [28, 'male', 31.68, 0, 'yes', 'southeast', 34672.1472],\n","    [43, 'female', 35.64, 1, 'no', 'southeast', 7345.7266],\n","    [49, 'male', 28.69, 3, 'no', 'northwest', 10264.4421],\n","    [41, 'male', 23.94, 1, 'no', 'northeast', 6858.4796],\n","    [30, 'male', 25.46, 0, 'no', 'northeast', 3645.0894],\n","    [48, 'female', 33.33, 0, 'no', 'southeast', 8283.6807],\n","    [35, 'female', 35.86, 2, 'no', 'southeast', 5836.5204],\n","    [56, 'female', 35.8, 1, 'no', 'southwest', 11674.13],\n","    [25, 'female', 32.23, 1, 'no', 'southeast', 18218.16139]\n","]\n","\n","warnings.filterwarnings(\"ignore\") #suppress warnings"],"metadata":{"id":"JSB2mpxNuEHW","executionInfo":{"status":"ok","timestamp":1698284042521,"user_tz":420,"elapsed":7817,"user":{"displayName":"Michael Roslyak","userId":"12077079961407806668"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"_flwU7-bytrT"}},{"cell_type":"markdown","source":["## Base Model Class (for All Models)"],"metadata":{"id":"efOYxdI_tHS5"}},{"cell_type":"code","source":["class BaseModel:\n","    def __init__(self, filepath):\n","\n","        # Load dataset from provided filepath\n","        self.dataset = pd.read_csv(filepath)\n","\n","        # Create a backup of the original dataset\n","        self.dataset_original = self.dataset.copy()\n","\n","        # Initializing instance-level variables for data and data splits\n","        self.x = None\n","        self.y = None\n","        self.x_train = None\n","        self.x_cv = None\n","        self.x_test = None\n","        self.y_train = None\n","        self.y_cv = None\n","        self.y_test = None\n","\n","        # Dictionaries to store StandardScaler and LabelEncoder objects\n","        self.scalers = {}\n","        self.encoders = {}\n","\n","        # Start data preprocessing (encoding, splitting, scaling)\n","        self.preprocess_data()\n","\n","    def preprocess_data(self):\n","        \"\"\"  Main preprocessing function that encodes categorical features, splits the data, and scales the features. \"\"\"\n","        self.encode_categorical()\n","        self.split_data()\n","        self.feature_scaling()\n","\n","    def encode_categorical(self):\n","        \"\"\"  Encodes categorical columns in the dataset using the LabelEncoder. \"\"\"\n","\n","        # Convert given columns to 'category' dtype\n","        self.dataset[['sex', 'smoker', 'region']] = self.dataset[['sex', 'smoker', 'region']].astype('category')\n","\n","        # Loop through columns and encode them using LabelEncoder\n","        for col in ['sex', 'smoker', 'region']:\n","            label = LabelEncoder()\n","\n","            # Store each encoder in the dictionary for potential use later\n","            self.encoders[col] = label\n","            self.dataset[col] = label.fit_transform(self.dataset[col])\n","\n","    def split_data(self):\n","        \"\"\" Splits the data into training, cross-validation, and test sets using a 70-15-15 split. \"\"\"\n","        # Separate features and target variable\n","        self.x = self.dataset.drop('charges', axis=1).values\n","        self.y = self.dataset['charges'].values\n","        # Split data into training and temporary sets (70-30 split)\n","        self.x_train, x_temp, self.y_train, y_temp = train_test_split(self.x, self.y, train_size=0.7, random_state=42)\n","        # Further split the temporary set into cross-validation and test sets (50-50 split)\n","        self.x_cv, self.x_test, self.y_cv, self.y_test = train_test_split(x_temp, y_temp, train_size=0.5, random_state=42)\n","\n","\n","\n","    def feature_scaling(self):\n","        \"\"\" Applies feature scaling (standardization) on training, cross-validation, and test data.  \"\"\"\n","\n","        scaler = StandardScaler()\n","\n","        # Store the scaler object for potential inverse scaling later\n","        self.scalers['x'] = scaler\n","\n","\n","        # Convert DataFrame slices to numpy arrays before scaling\n","        self.x_train = scaler.fit_transform(self.x_train.astype(float))  # Fit and transform training data\n","        self.x_cv = scaler.transform(self.x_cv.astype(float))\n","        self.x_test = scaler.transform(self.x_test.astype(float))\n","\n","        # Transform (using training data mean and std dev) cross-validation and test data\n","        #self.x_train = scaler.fit_transform(self.x_train)  # Fit and transform training data\n","        #self.x_cv = scaler.transform(self.x_cv)\n","        #self.x_test = scaler.transform(self.x_test)\n","\n","    def train(self):\n","        # Placeholder for the training method to be implemented by subclasses\n","        raise NotImplementedError(\"Train method not implemented\")\n","\n","    def predict(self, x):\n","        # Placeholder for the prediction method to be implemented by subclasses\n","        raise NotImplementedError(\"Predict method not implemented\")\n","\n","    def preprocess_new_data(self, x):\n","        \"\"\"Preprocess new input data in the same way as the training data.\"\"\"\n","        df = pd.DataFrame(x, columns=self.dataset_original.drop('charges', axis=1).columns)\n","\n","        # Encode categorical columns\n","        for col, encoder in self.encoders.items():\n","            df[col] = encoder.transform(df[col])\n","\n","        # Scale the features\n","        x_scaled = self.scalers['x'].transform(df)\n","        return x_scaled\n","\n","\n","    def inverse_transform(self, x, y):\n","        \"\"\"\n","        Inverse transforms feature scaled and label encoded data.\n","        Helpful for visualization or further processing on original scale.\n","        \"\"\"\n","\n","        x = pd.DataFrame(self.scalers['x'].inverse_transform(x), columns=self.dataset_original.drop('charges', axis=1).columns)\n","\n","        # Loop through encoded columns and inverse transform them\n","        for col, encoder in self.encoders.items():\n","            x[col] = encoder.inverse_transform(x[col].astype(int))\n","        return x, y\n","\n","    def plot_features_vs_target(self):\n","        \"\"\"\n","        Plots various features against the target variable to understand their relationship.\n","        \"\"\"\n","\n","        # Define subplots layout\n","        fig, axs = plt.subplots(2, 2, figsize=(10, 7))\n","\n","        # Plot using the original (non-encoded, non-scaled) dataset\n","        sns.barplot(x='region', y='charges', hue='smoker', data=self.dataset_original, ax=axs[0, 0])\n","        axs[0, 0].set_title('Region vs Charges')\n","        sns.barplot(x='children', y='charges', hue='smoker', data=self.dataset_original, ax=axs[0, 1])\n","        axs[0, 1].set_title('Children vs Charges')\n","        sns.scatterplot(x='age', y='charges', hue='smoker', data=self.dataset_original, ax=axs[1, 0])\n","        axs[1, 0].set_title('Age vs Charges')\n","        sns.scatterplot(x='bmi', y='charges', hue='smoker', data=self.dataset_original, ax=axs[1, 1])\n","        axs[1, 1].set_title('BMI vs Charges')\n","\n","        # Set main title for all plots\n","        fig.suptitle(\"Dataset Analysis\", fontsize=16)\n","        plt.tight_layout()\n","        plt.show()\n","\n","    def plot_dataset_split_distribution(self):\n","        \"\"\"\n","        Plots the distribution of the dataset after splitting into training, cross-validation, and test sets.\n","        Aids in understanding the distribution of data across the splits.\n","        \"\"\"\n","\n","        # Inverse transform data splits for visualization\n","        df_X_train, df_y_train = self.inverse_transform(self.x_train, self.y_train)\n","        df_X_cv, df_y_cv = self.inverse_transform(self.x_cv, self.y_cv)\n","        df_X_test, df_y_test = self.inverse_transform(self.x_test, self.y_test)\n","\n","\n","        # Convert numpy arrays to DataFrames for easier plotting\n","        df_y_train = pd.DataFrame(df_y_train, columns=['charges'])\n","        df_y_cv = pd.DataFrame(df_y_cv, columns=['charges'])\n","        df_y_test = pd.DataFrame(df_y_test, columns=['charges'])\n","\n","        # Concatenate features and target to form complete datasets for each split\n","        df_train = pd.concat([df_X_train, df_y_train], axis=1)\n","        df_cv = pd.concat([df_X_cv, df_y_cv], axis=1)\n","        df_test = pd.concat([df_X_test, df_y_test], axis=1)\n","\n","        # Define subplots layout\n","        fig, axes = plt.subplots(1, 3, figsize=(12, 4))\n","        sns.scatterplot(x='age', y='charges', data=df_train, ax=axes[0])\n","        axes[0].set_title('Age vs Charges (Train)')\n","        sns.scatterplot(x='age', y='charges', data=df_cv, ax=axes[1])\n","        axes[1].set_title('Age vs Charges (CV)')\n","        sns.scatterplot(x='age', y='charges', data=df_test, ax=axes[2])\n","        axes[2].set_title('Age vs Charges (Test)')\n","\n","        fig.suptitle(\"Dataset Split Distribution\", fontsize=16)\n","        plt.tight_layout()\n","        plt.show()\n"],"metadata":{"id":"DJFUJXrOtEmV","executionInfo":{"status":"ok","timestamp":1698284042522,"user_tz":420,"elapsed":25,"user":{"displayName":"Michael Roslyak","userId":"12077079961407806668"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Linear Regression Model Class"],"metadata":{"id":"b6x7KK3etelW"}},{"cell_type":"code","source":["\n","\n","class LinearModel(BaseModel):\n","    def __init__(self, filepath):\n","        \"\"\"Initializing the base model and setting up the linear model.\"\"\"\n","\n","        super().__init__(filepath)\n","        self.model = None\n","        self.train()\n","\n","    def train(self):\n","        \"\"\"Trains the linear regression model\"\"\"\n","        self.model = LinearRegression()\n","        self.model.fit(self.x_train, self.y_train)\n","\n","\n","    def predict(self, x):\n","        \"\"\"Predicts target values using the trained linear regression model\"\"\"\n","\n","        if self.model is None:\n","            raise ValueError(\"Model has not been trained. Call the train method first.\")\n","\n","        x_preprocessed = self.preprocess_new_data(x)\n","        return self.model.predict(x_preprocessed)\n","\n","    def print_results(self):\n","        \"\"\"Prints the performance metrics of the model for CV and test sets.\"\"\"\n","\n","        # Predictions on test set\n","        y_pred_test = self.model.predict(self.x_test)\n","        test_score = r2_score(self.y_test, y_pred_test)\n","\n","        # Predictions on CV set\n","        y_pred_cv = self.model.predict(self.x_cv)\n","        cv_score = r2_score(self.y_cv, y_pred_cv)\n","\n","        # Print scores\n","        print(f\"Linear Model Score (CV): {cv_score * 100:.2f}%\")\n","        print(f\"Linear Model Score (Test Set): {test_score * 100:.2f}%\")\n"],"metadata":{"id":"QSdtfJ2DtXS-","executionInfo":{"status":"ok","timestamp":1698284042522,"user_tz":420,"elapsed":23,"user":{"displayName":"Michael Roslyak","userId":"12077079961407806668"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["## Polynomial Regression Model Class"],"metadata":{"id":"GqwPuzxetj_c"}},{"cell_type":"code","source":["class PolynomialRegressionModel(BaseModel):\n","\n","\n","    def __init__(self, filepath):\n","        \"\"\"Initializing base model and setting hyperparameters.\"\"\"\n","\n","        super().__init__(filepath)\n","\n","        self.alphas = [0.01, 0.1, 0.5, 1, 10, 100, 500, 1000]\n","        self.degrees = list(range(1, 5))\n","\n","        #Lists to store errors and scores for different hyperparameters.\n","        self.train_errors_degree = []\n","        self.cv_errors_degree = []\n","        self.scores_degree = []\n","\n","        self.train_errors_alpha = []\n","        self.cv_errors_alpha = []\n","        self.scores_alpha = []\n","\n","        # Default values for best hyperparameters\n","        self.best_degree = 2\n","        self.best_alpha = 1\n","        self.best_model = None\n","        self.poly = None\n","\n","        self.train()\n","\n","\n","    def train(self):\n","        \"\"\"Training logic to find best hyperparameters and initialize best model.\"\"\"\n","\n","        self.find_best_degree()\n","        self.find_best_alpha_ridge()\n","        self.initialize_best_model()\n","\n","\n","    def initialize_best_model(self):\n","        \"\"\"Initialize the best model based on best hyperparameters found.\"\"\"\n","\n","        self.poly = PolynomialFeatures(degree=self.best_degree)\n","        x_train_pol = self.poly.fit_transform(self.x_train)\n","\n","        if self.best_alpha == 0:\n","            self.best_model = LinearRegression()\n","        else:\n","            self.best_model = Ridge(alpha=self.best_alpha)\n","\n","        self.best_model.fit(x_train_pol, self.y_train)\n","\n","\n","    def find_best_degree(self):\n","        \"\"\"Find the best polynomial degree for the model.\"\"\"\n","\n","        for degree in self.degrees:\n","            # Following the provided code for polynomial regression\n","            poly = PolynomialFeatures(degree=degree)\n","            x_train_pol = poly.fit_transform(self.x_train)\n","            x_cv_pol = poly.transform(self.x_cv)\n","            x_test_pol = poly.transform(self.x_test)\n","\n","            poly_reg = LinearRegression()\n","            poly_reg.fit(x_train_pol, self.y_train)\n","\n","            y_train_pred = poly_reg.predict(x_train_pol)\n","            y_cv_pred = poly_reg.predict(x_cv_pol)\n","\n","            train_error = mean_squared_error(self.y_train, y_train_pred)\n","            cv_error = mean_squared_error(self.y_cv, y_cv_pred)\n","\n","            y_test_pred = poly_reg.predict(x_test_pol)\n","            score = r2_score(self.y_test, y_test_pred)\n","            self.train_errors_degree.append(train_error)\n","            self.cv_errors_degree.append(cv_error)\n","            self.scores_degree.append(score)\n","\n","        self.best_degree = np.argmin(self.cv_errors_degree) + 1\n","\n","    def find_best_alpha_ridge(self):\n","        \"\"\"Find the best alpha value for Ridge regularization.\"\"\"\n","\n","        poly = PolynomialFeatures(degree=self.best_degree)\n","        x_train_pol = poly.fit_transform(self.x_train)\n","        x_cv_pol = poly.transform(self.x_cv)\n","        x_test_pol = poly.transform(self.x_test)\n","\n","        for alpha in self.alphas:\n","            ridge_reg = Ridge(alpha=alpha)\n","            ridge_reg.fit(x_train_pol, self.y_train)\n","\n","            y_train_pred = ridge_reg.predict(x_train_pol)\n","            y_cv_pred = ridge_reg.predict(x_cv_pol)\n","            train_error = mean_squared_error(self.y_train, y_train_pred)\n","            cv_error = mean_squared_error(self.y_cv, y_cv_pred)\n","            score = ridge_reg.score(x_test_pol, self.y_test)\n","\n","            self.train_errors_alpha.append(train_error)\n","            self.cv_errors_alpha.append(cv_error)\n","            self.scores_alpha.append(score)\n","\n","        self.best_alpha = self.alphas[np.argmin(self.cv_errors_alpha)]\n","\n","    def predict(self, x_new):\n","        \"\"\"Predict the output based on new input data using the best model.\"\"\"\n","\n","        # Preprocess the new data\n","        x_new_processed = self.preprocess_new_data(x_new)\n","\n","        x_new_pol = self.poly.fit_transform(x_new_processed)\n","\n","        # Predict using the best model\n","        predictions = self.best_model.predict(x_new_pol)\n","\n","        return predictions\n","\n","    def plot_results(self):\n","        \"\"\"Plot the performance metrics vs hyperparameters.\"\"\"\n","\n","        # Get degrees and alphas\n","        degrees = self.degrees\n","        alphas = self.alphas\n","\n","        fig, axs = plt.subplots(2, 2, figsize=(10, 7))\n","\n","        # Adding a main title for the entire figure\n","        fig.suptitle(\"Analysis of Model's Performance\", fontsize=16, y=1.08)\n","\n","\n","        # First Row - For degree\n","        axs[0, 0].plot(degrees, self.train_errors_degree, label=\"Train Error\", marker='o')\n","        axs[0, 0].plot(degrees, self.cv_errors_degree, label=\"CV Error\", marker='o')\n","        axs[0, 0].set_xlabel('Degree')\n","        axs[0, 0].set_ylabel('Error')\n","        axs[0, 0].set_title('Train & CV Error vs Degree')\n","        axs[0, 0].legend()\n","\n","        axs[0, 1].plot(degrees, self.scores_degree, label=\"Score\", marker='o')\n","        axs[0, 1].set_xlabel('Degree')\n","        axs[0, 1].set_ylabel('R^2 Score')\n","        axs[0, 1].set_title('Score vs Degree')\n","        axs[0, 1].legend()\n","\n","        # Second Row - For alpha\n","        axs[1, 0].plot(alphas, self.train_errors_alpha, label=\"Train Error\", marker='o')\n","        axs[1, 0].plot(alphas, self.cv_errors_alpha, label=\"CV Error\", marker='o')\n","        axs[1, 0].set_xlabel('Alpha')\n","        axs[1, 0].set_ylabel('Error')\n","        axs[1, 0].set_title('Train & CV Error vs Alpha')\n","        axs[1, 0].legend()\n","\n","        axs[1, 1].plot(alphas, self.scores_alpha, label=\"Score\", marker='o')\n","        axs[1, 1].set_xlabel('Alpha')\n","        axs[1, 1].set_ylabel('R^2 Score')\n","        axs[1, 1].set_title('Score vs Alpha')\n","        axs[1, 1].legend()\n","\n","        plt.tight_layout()\n","        plt.show()\n","\n","    def print_results(self):\n","        \"\"\"Print the performance of the model and best hyperparameters.\"\"\"\n","\n","        poly = PolynomialFeatures(degree=self.best_degree)\n","        x_cv_pol = poly.fit_transform(self.x_cv)\n","        x_test_pol = poly.fit_transform(self.x_test)\n","\n","        y_cv_pred = self.best_model.predict(x_cv_pol)\n","        y_test_pred = self.best_model.predict(x_test_pol)\n","\n","        print(f\"Polynomial Model Score (CV): {r2_score(self.y_cv, y_cv_pred) * 100:.2f}%\")\n","        print(f\"Polynomial Model Score (Test): {r2_score(self.y_test, y_test_pred) * 100:.2f}%\\n\")\n","        print(f\"Best degree: {self.best_degree}\")\n","        print(f\"Best alpha: {self.best_alpha}\\n\")"],"metadata":{"id":"Mzq8gFqbtm7Y","executionInfo":{"status":"ok","timestamp":1698284042759,"user_tz":420,"elapsed":259,"user":{"displayName":"Michael Roslyak","userId":"12077079961407806668"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["## Neural Network Model Class"],"metadata":{"id":"Js1R-82ttu-v"}},{"cell_type":"code","source":["class NeuralNetworkModel(BaseModel):\n","\n","    def __init__(self, filepath):\n","        \"\"\"Initialize the NeuralNetwork model with a default architecture.\"\"\"\n","\n","        super().__init__(filepath)\n","        self.model = Sequential(\n","            [\n","                Dense(64, activation='relu',  name=\"L1\"),\n","                Dense(128, activation='relu', name=\"L2\"),\n","                Dense(64, activation='relu', name=\"L3\"),\n","                Dense(1, activation='linear', name=\"L_Output\"),\n","            ],\n","            name=\"default_model\"\n","        )\n","\n","        self.train()\n","\n","\n","\n","    def train(self):\n","        \"\"\"Train the neural network using Adam optimizer and mean squared error loss.\"\"\"\n","\n","        optimizer = keras.optimizers.Adam(learning_rate=0.01)\n","        self.model.compile(optimizer=optimizer, loss='mean_squared_error')\n","\n","        self.history = self.model.fit(\n","            self.x_train, self.y_train,\n","            epochs=100,\n","            batch_size=16,\n","            validation_data=(self.x_cv, self.y_cv),\n","            verbose=0\n","        )\n","\n","    def plot_results(self):\n","        \"\"\"Plot training and validation loss over epochs.\"\"\"\n","\n","        plt.figure(figsize=(9, 5))\n","        plt.plot(self.history.history['loss'], label='Training Loss')\n","        plt.plot(self.history.history['val_loss'], label='Validation Loss')\n","        plt.title('Training and Validation Loss')\n","        plt.xlabel('Epochs')\n","        plt.ylabel('Mean Squared Error')\n","        plt.legend()\n","        plt.show()\n","\n","    def predict(self, x_new):\n","        \"\"\"Predict the output for new data using the trained neural network.\"\"\"\n","\n","        # Preprocess the new data\n","        x_new_processed = self.preprocess_new_data(x_new)\n","\n","        # Get predictions using the neural network model\n","        predictions = self.model.predict(x_new_processed)\n","\n","        return predictions.ravel()\n","\n","\n","    def print_results(self):\n","        \"\"\"Print model performance on CV and test datasets.\"\"\"\n","\n","        # Predictions on test set\n","        y_pred_test = self.model.predict(self.x_test)\n","        test_score = r2_score(self.y_test, y_pred_test)\n","\n","        # Predictions on CV set\n","        y_pred_cv = self.model.predict(self.x_cv)\n","        cv_score = r2_score(self.y_cv, y_pred_cv)\n","\n","        # Print scores\n","        print(f\"Neural Network Model Score (CV): {cv_score * 100:.2f}%\")\n","        print(f\"Neural Network Model Score (Test Set): {test_score * 100:.2f}%\")"],"metadata":{"id":"JJ3xUo2Mts7N","executionInfo":{"status":"ok","timestamp":1698284042760,"user_tz":420,"elapsed":15,"user":{"displayName":"Michael Roslyak","userId":"12077079961407806668"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Random Forest Regression Model Class"],"metadata":{"id":"P0gBUXZ4t3qa"}},{"cell_type":"code","source":["class RandomForestModel(BaseModel):\n","\n","    def __init__(self, filepath):\n","        \"\"\"Initialize the RandomForest model with default hyperparameters.\"\"\"\n","\n","        super().__init__(filepath)\n","\n","        # this has been found to be the best configuration through hyperparameter_tuning()\n","        self.default_params = {\n","            'bootstrap': False,\n","            'criterion': 'friedman_mse',\n","            'max_depth': 20,\n","            'max_features': 'sqrt',\n","            'min_samples_leaf': 2,\n","            'min_samples_split': 10,\n","            'n_estimators': 100,\n","            'random_state': 1  # for reproducibility\n","        }\n","\n","        # Initializing best_params with default parameters\n","        self.best_params_ = self.default_params\n","\n","\n","        self.model = RandomForestRegressor(**self.default_params)\n","\n","        self.train()\n","\n","    def train(self):\n","        \"\"\"Train the model on the provided data.\"\"\"\n","\n","        self.model.fit(self.x_train, self.y_train)\n","\n","\n","    def hyperparameter_tuning(self):\n","        \"\"\"Tune hyperparameters using GridSearchCV.\"\"\"\n","\n","        # Define the hyperparameters and their possible values\n","        param_grid = {\n","            'criterion': ['friedman_mse','mse', 'mae'],\n","            'n_estimators': [10, 50, 100, 200],\n","            'max_features': ['auto', 'sqrt'],\n","            'max_depth': [None, 10, 20, 30, 40, 50],\n","            'min_samples_split': [2, 5, 10],\n","            'min_samples_leaf': [1, 2, 4],\n","            'bootstrap': [True, False]\n","        }\n","\n","        # Initialize GridSearchCV\n","        grid_search = GridSearchCV(estimator=self.model, param_grid=param_grid,\n","                                   cv=3, n_jobs=-1, verbose=0)\n","\n","        # Fit the model\n","        grid_search.fit(self.x_train, self.y_train)\n","\n","        # Update the model with the best hyperparameters\n","        self.model = grid_search.best_estimator_\n","        self.best_params_ = grid_search.best_params_\n","        print(f\"Best Parameters: {grid_search.best_params_}\")\n","\n","    def predict(self, x_new):\n","        \"\"\"Make predictions based on new input data.\"\"\"\n","\n","        x_new_processed = self.preprocess_new_data(x_new)\n","\n","        # Get predictions using the random forest model\n","        predictions = self.model.predict(x_new_processed)\n","\n","        return predictions\n","\n","\n","\n","\n","    def print_results(self):\n","        \"\"\"Print model scores on CV and test datasets.\"\"\"\n","\n","        # Predictions on test set\n","        y_pred_test = self.model.predict(self.x_test)\n","        test_score = r2_score(self.y_test, y_pred_test)\n","\n","        # Predictions on CV set\n","        y_pred_cv = self.model.predict(self.x_cv)\n","        cv_score = r2_score(self.y_cv, y_pred_cv)\n","\n","        # Print scores\n","        print(f\"Random Forest Model Score (CV): {cv_score * 100:.2f}%\")\n","        print(f\"Random Forest Score (Test Set): {test_score * 100:.2f}%\")\n","\n","\n","\n","    def print_feature_importance(self):\n","\n","        print(\"\\n\\nThe most important features are:\")\n","        importances = self.model.feature_importances_\n","        std = np.std([tree.feature_importances_ for tree in self.model.estimators_],axis=0)\n","        indices = np.argsort(importances)[::-1]\n","        variables = ['age', 'sex', 'bmi', 'children','smoker', 'region']\n","        importance_list = []\n","        for f in range(self.x.shape[1]):\n","            variable = variables[indices[f]]\n","            importance_list.append(variable)\n","            print(\"%d.%s(%.2f%%)\" % (f + 1, variable, importances[indices[f]] * 100))\n","\n","\n","    def plot_feature_importance(self):\n","        \"\"\"Plot a bar chart showing the importance of each feature.\"\"\"\n","\n","        # Get the importances and standard deviations\n","        importances = self.model.feature_importances_\n","        std = np.std([tree.feature_importances_ for tree in self.model.estimators_], axis=0)\n","        indices = np.argsort(importances)[::-1]\n","        variables = ['age', 'sex', 'bmi', 'children', 'smoker', 'region']\n","\n","        # Plot the feature importances\n","        plt.figure(figsize=(8, 4))\n","        plt.title(\"Feature Importances\")\n","        plt.bar(range(self.x.shape[1]), importances[indices], yerr=std[indices], align=\"center\", color=\"lightblue\", edgecolor=\"black\")\n","        plt.xticks(range(self.x.shape[1]), [variables[i] for i in indices], rotation=45)\n","\n","        # Adjust y-axis to display percentages\n","        y_vals = plt.gca().get_yticks()\n","        plt.gca().set_yticklabels(['{:,.2%}'.format(x) for x in y_vals])\n","\n","        plt.xlim([-1, self.x.shape[1]])\n","        plt.tight_layout()\n","        plt.show()\n","\n","\n","\n"],"metadata":{"id":"mt0prgnLt7ep","executionInfo":{"status":"ok","timestamp":1698284042760,"user_tz":420,"elapsed":13,"user":{"displayName":"Michael Roslyak","userId":"12077079961407806668"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["# User Interface"],"metadata":{"id":"3gqKLnK0uPh5"}},{"cell_type":"markdown","source":["### Analyze Raw Data Menu"],"metadata":{"id":"kReus8yCx56u"}},{"cell_type":"code","source":["def menu_analyze_raw_data():\n","    \"\"\"Menu for analyzing raw dataset.\"\"\"\n","\n","    # ASCII art for the title\n","    tprint(\"Raw Data Analysis\")\n","\n","    print(\"ðŸ“Š The following plot will help visualize and analyze the relationship between various features (independent variables) and the target variable (dependent variable) in the dataset. \\nIt provides insights into how different features influence the target variable.\")\n","    #input(str_pressEnter)\n","\n","    base = BaseModel(filepath)\n","    base.plot_features_vs_target()\n","\n","\n","    print(\"\\n\\nðŸ“Š The following plot will help visualize the distribution of the dataset after it has been split into training, cross-validation, and test sets. \\nIt aids in understanding how the data is distributed across these splits.\")\n","    #input(str_pressEnter)\n","\n","    base = BaseModel(filepath)\n","    base.plot_dataset_split_distribution()\n"],"metadata":{"id":"B5LBN_0Jx9N-","executionInfo":{"status":"ok","timestamp":1698284042760,"user_tz":420,"elapsed":12,"user":{"displayName":"Michael Roslyak","userId":"12077079961407806668"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### Prediction Menu"],"metadata":{"id":"_p3Ajo05xn2e"}},{"cell_type":"code","source":["def print_predictions(predictions, model_name, target=None):\n","    \"\"\"Display the predicted charges in more readable format.\"\"\"\n","\n","    print(f\"\\nPredicted Charges ({GREEN}{model_name}{END})\")\n","    for i, prediction in enumerate(predictions):\n","        formatted_prediction = f\"{YELLOW}${prediction:.2f}{END}\"\n","        if target is not None:\n","            formatted_target = f\"{YELLOW}${target[i]:.2f}{END}\"\n","            formatted_difference = f\"{YELLOW}${abs(target[i]-prediction):.2f}{END}\"\n","            print(f\" {i + 1}: Predicted: {formatted_prediction}, \\t Actual: {formatted_target} \\t Difference: {formatted_difference}\")\n","        else:\n","            print(f\" {i + 1}: {formatted_prediction}\")\n","\n","\n","def models_performance_comparison(x_pred = [], target = None):\n","    \"\"\"Compare performance of different models.\"\"\"\n","\n","    if x_pred is None or len(x_pred) == 0:\n","        x_pred = [row[:-1] for row in test_dataset]\n","        target = [row[-1] for row in test_dataset]\n","\n","    print(str_separator)\n","    predictions_linear = model_linear.predict(x_pred)\n","    predictions_poly = model_poly.predict(x_pred)\n","    predictions_nn = model_nn.predict(x_pred)\n","    predictions_forest = model_forest.predict(x_pred)\n","\n","\n","    print_predictions(predictions_linear, \"linear\", target)\n","    print_predictions(predictions_poly, \"poly\", target)\n","    print_predictions(predictions_nn, \"nn\", target)\n","    print(f\"\\n\\n{BOLD}Recommended model: {END}\")\n","    print_predictions(predictions_forest, \"forest\", target)\n","\n","\n","\n","    input(str_pressEnter)\n","\n","\n","def menu_prediction():\n","    \"\"\"Menu for prediction options.\"\"\"\n","    while True:\n","        print(str_separator)\n","        tprint(\"Prediction Menu\")\n","        print(\"1. Use Sample Data\")\n","        print(\"2. Enter Your Own Data\")\n","        print(\"0. Back to Main Menu\\n\")\n","\n","        choice = input(str_choiceSelection)\n","\n","        if choice == '1':\n","            models_performance_comparison()\n","        elif choice == '2':\n","            while True:\n","\n","                print(f\"\\n{BOLD}Format {END}: {YELLOW} age, sex, bmi, children, smoker, region {END} (include commas between values)...\")\n","                print(f\"{BOLD}Example {END}: 30, male, 25.5, 2, no, southwest\\n\")\n","                input_str = input(f\"Enter data (or '0' to go back to the previous menu):\")\n","\n","                if input_str.lower() == '0':\n","                    break\n","\n","                data = input_str.split(',')\n","\n","\n","                str_invalidInput = f\"{RED}Invalid input! {END}\"\n","                if len(data) != 6:\n","                    print(f\"{str_invalidInput} Please enter data in the correct format.\")\n","                    continue\n","\n","                try:\n","                    age = int(data[0])\n","                    sex = data[1].strip().lower()\n","                    bmi = float(data[2])\n","                    children = int(data[3])\n","                    smoker = data[4].strip().lower()\n","                    region = data[5].strip().lower()\n","\n","                    # Perform checks on the data\n","                    if age <= 0:\n","                        print(f\"{str_invalidInput} Age must be a positive integer.\")\n","                        continue\n","                    if sex not in ['male', 'female']:\n","                        print(f\"{str_invalidInput} Sex must be 'male' or 'female'.\")\n","                        continue\n","                    if bmi <= 0:\n","                        print(f\"{str_invalidInput} BMI must be a positive number.\")\n","                        continue\n","                    if not (0 <= children <= 10):\n","                        print(f\"{str_invalidInput} Children must be an integer between 0 and 10.\")\n","                        continue\n","                    if smoker not in ['yes', 'no']:\n","                        print(f\"{str_invalidInput} Smoker must be 'yes' or 'no'.\")\n","                        continue\n","                    if region not in ['southwest', 'southeast', 'northwest', 'northeast']:\n","                        print(f\"{str_invalidInput} Region must be 'southwest', 'southeast', 'northwest', or 'northeast'.\")\n","                        continue\n","\n","                    # Data is valid, use it for prediction\n","                    x_pred = [[age, sex, bmi, children, smoker, region]]\n","\n","                    models_performance_comparison(x_pred)\n","\n","\n","\n","                except ValueError as e:\n","                    print(f\"Error: {e}\")\n","                    print(\"Invalid input. Please enter data in the correct format.\")\n","                    continue\n","\n","        elif choice == '0':\n","            break\n","        else:\n","            print(\"Invalid choice. Please try again.\")"],"metadata":{"id":"KDjb8QLBxsB5","executionInfo":{"status":"ok","timestamp":1698284042761,"user_tz":420,"elapsed":12,"user":{"displayName":"Michael Roslyak","userId":"12077079961407806668"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Model Training Results Menu"],"metadata":{"id":"jPIgt28syGih"}},{"cell_type":"code","source":["def menu_training_results():\n","    \"\"\"Menu to display model training results.\"\"\"\n","\n","    print(str_separator)\n","    tprint(\"Training Results\")\n","\n","    # Linear Regression\n","    model_linear.print_results()\n","    input(str_pressEnter)\n","\n","    # Polynomial Regression\n","    print(str_separator)\n","    model_poly.print_results()\n","\n","    print(\"\\nðŸ“Š The following plots represents the performance metrics of polynomial models against various polynomial degree and alphas.\\n\")\n","    input(str_pressEnter)\n","\n","    model_poly.plot_results()\n","    input(str_pressEnter)\n","\n","    # Neural Networks\n","    print(str_separator)\n","    model_nn.print_results()\n","\n","    print(\"\\nðŸ“Š The following plot represents the performance metrics of Neural Network during training.\\n\")\n","    input(str_pressEnter)\n","\n","    model_nn.plot_results()\n","    input(str_pressEnter)\n","\n","    # Random Forest\n","    print(str_separator)\n","    model_forest.print_results()\n","\n","    print(\"\\nðŸ“Š The following plot represents how much each feature influences the cost of insurance.\\n\")\n","    input(str_pressEnter)\n","\n","    model_forest.plot_feature_importance()\n","    input(str_pressEnter)"],"metadata":{"id":"RV8pR8PbyFF_","executionInfo":{"status":"ok","timestamp":1698284042761,"user_tz":420,"elapsed":9,"user":{"displayName":"Michael Roslyak","userId":"12077079961407806668"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### Main Menu"],"metadata":{"id":"sb-YmSelySI8"}},{"cell_type":"code","source":["\n","\n","def main_menu():\n","    \"\"\"Main menu for the program.\"\"\"\n","    while True:\n","        tprint(\"Main Menu\")\n","        print(\"1. Analyze Raw Data\")\n","        print(\"2. Show the Models' Training Results\")\n","        print(\"3. Predict the Cost of Insurance\")\n","        print(\"0. Exit\\n\")\n","\n","        choice = input(str_choiceSelection)\n","\n","        if choice == '1':\n","            menu_analyze_raw_data()\n","        elif choice == '2':\n","            menu_training_results()\n","        elif choice == '3':\n","            menu_prediction()\n","        elif choice == '0':\n","            break\n","        else:\n","            print(\"Invalid choice. Please try again.\")\n","\n"],"metadata":{"id":"PnD8Sa-JuTR6","executionInfo":{"status":"ok","timestamp":1698284042761,"user_tz":420,"elapsed":8,"user":{"displayName":"Michael Roslyak","userId":"12077079961407806668"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["# Program's Starting Point"],"metadata":{"id":"pQX3q42PwMLA"}},{"cell_type":"code","source":["\n","\n","# =========================================================================\n","#                      Program's Starting Point\n","# =========================================================================\n","\n","\n","\n","tprint(\"Hello\")\n","\n","print(\n","    f\"{GREEN}{BOLD}ðŸ‘‹ Welcome to the Intelligent Premium Estimator!{END}\\n\\n\"\n","    f\"In the upcoming steps, we'll be training four different machine learning models to predict insurance costs:\\n\"\n","    f\"\\t{BOLD}1. Linear Regression Model{END}\\n\"\n","    f\"\\t{BOLD}2. Polynomial Regression Model{END}\\n\"\n","    f\"\\t{BOLD}3. Neural Network Model{END}\\n\"\n","    f\"\\t{BOLD}4. Random Forest Regression Model{END}\\n\\n\"\n","    f\"Our goal is to evaluate the performance of each model and determine which one provides the most accurate predictions.\\n\"\n","    f\"After training, you'll be able to view detailed results and even predict insurance costs based on custom inputs.\\n\\n\"\n","    f\"{BOLD}Let's dive in!{END}\"\n",")\n","\n","\n","\n","choice = input(str_pressEnter)\n","print(\"Please wait while we train our models...\\n\\n\")\n","\n","# train our models\n","model_linear = LinearModel(filepath)\n","model_poly = PolynomialRegressionModel(filepath)\n","model_nn = NeuralNetworkModel(filepath)\n","model_forest = RandomForestModel(filepath)\n","\n","\n","main_menu()"],"metadata":{"id":"kh6qmyfiwPAl"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"provenance":[],"collapsed_sections":["yQvEmM6jgkIJ","_flwU7-bytrT","efOYxdI_tHS5","b6x7KK3etelW","GqwPuzxetj_c","Js1R-82ttu-v","P0gBUXZ4t3qa","3gqKLnK0uPh5","kReus8yCx56u","_p3Ajo05xn2e","jPIgt28syGih","sb-YmSelySI8","pQX3q42PwMLA"]}},"nbformat":4,"nbformat_minor":0}